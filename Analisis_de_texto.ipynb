{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d404fb8",
   "metadata": {},
   "source": [
    "Analisis de texto\n",
    "\n",
    "- representa el texto como una matriz de frecuencia de palabras\n",
    "\n",
    "- partir el texto en tokens\n",
    "\n",
    "- cuenta las ocurrencias de cada uno de los tokens\n",
    "\n",
    "- asigna valores de un vector de acuerdo a numero de ocurrencias\n",
    "\n",
    "https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "466257ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Time is a flat circle.\",   \n",
    "    \"The world needs bad men. We keep the other bad men from the door.\",\n",
    "    \"I think human consciousness is a tragic misstep in evolution.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f109de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae4f0559",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_vectorizer = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "daa3c431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 22 stored elements and shape (3, 21)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_vectorizer # Get the feature names after transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "872d95c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 2, 0, 1, 1, 3, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_vectorizer.toarray()  # Convert the document-term matrix to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d6f3c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': 17, 'is': 9, 'flat': 5, 'circle': 1, 'the': 15, 'world': 20, 'needs': 13, 'bad': 0, 'men': 11, 'we': 19, 'keep': 10, 'other': 14, 'from': 6, 'door': 3, 'think': 16, 'human': 7, 'consciousness': 2, 'tragic': 18, 'misstep': 12, 'in': 8, 'evolution': 4}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_) # Access the vocabulary dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb0d781e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['time', 'is', 'flat', 'circle'], dtype='<U13'),\n",
       " array(['the', 'world', 'needs', 'bad', 'men', 'we', 'keep', 'other',\n",
       "        'from', 'door'], dtype='<U13'),\n",
       " array(['is', 'think', 'human', 'consciousness', 'tragic', 'misstep', 'in',\n",
       "        'evolution'], dtype='<U13')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# se pierde el orden de las palabras\n",
    "vectorizer.inverse_transform(transformed_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "643a79b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_count_vectorizer = CountVectorizer(binary=True, max_features=10)\n",
    "modified_count_vectorizer.fit_transform(corpus).toarray()  # Fit and transform with binary counts and max features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8acfb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Convert the document-term matrix to an array with binary values\n",
    "\n",
    "#max_df_vectorizer = CountVectorizer(max_df=3) #means ignore terms that appear in more than 3 documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b33ad9b",
   "metadata": {},
   "source": [
    "No es la unica forma para trabajar con texto, pensar en palabras repetitivas como articulos \"el\" \"la\" \"con\" harian muy repetitiva la matriz, ya que los mas importantes serian las palabras que mas se repite, en este caso esas palabras repetitivas que no aportan nada al texto, quitandole prioridad a aquellas que si lo son\n",
    "\n",
    "- term frequency-inverse document frequency, es la alternativa cuando se pondera la importancia de cada palabra en funcion de la frecuencia con que aparece el corpus\n",
    "\n",
    "- HashingVectorizer  es util para trabajar con conjuntos de datos muy grandes que no caben en memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5488fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer,HashingVectorizer\n",
    "Tfidvectorizer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19a94a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfid_transformed = Tfidvectorizer.fit_transform(transformed_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9f7a159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 22 stored elements and shape (3, 21)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tfid_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a73d9ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.52863461, 0.        , 0.        , 0.        ,\n",
       "        0.52863461, 0.        , 0.        , 0.        , 0.40204024,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.52863461, 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.40824829, 0.        , 0.        , 0.20412415, 0.        ,\n",
       "        0.        , 0.20412415, 0.        , 0.        , 0.        ,\n",
       "        0.20412415, 0.40824829, 0.        , 0.20412415, 0.20412415,\n",
       "        0.61237244, 0.        , 0.        , 0.        , 0.20412415,\n",
       "        0.20412415],\n",
       "       [0.        , 0.        , 0.36325471, 0.        , 0.36325471,\n",
       "        0.        , 0.        , 0.36325471, 0.36325471, 0.27626457,\n",
       "        0.        , 0.        , 0.36325471, 0.        , 0.        ,\n",
       "        0.        , 0.36325471, 0.        , 0.36325471, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tfid_transformed.toarray()  # Convert the TF-IDF matrix to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65cf924a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad' 'circle' 'consciousness' 'door' 'evolution' 'flat' 'from' 'human'\n",
      " 'in' 'is' 'keep' 'men' 'misstep' 'needs' 'other' 'the' 'think' 'time'\n",
      " 'tragic' 'we' 'world']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())  # Get the feature names after transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434a4d35",
   "metadata": {},
   "source": [
    "\n",
    "Las diferencias principales entre CountVectorizer y TfidfVectorizer son:\n",
    "\n",
    "- CountVectorizer:\n",
    "  - Convierte el texto en una matriz de conteo de palabras (frecuencia absoluta de cada palabra en cada documento).\n",
    "  - No pondera la importancia de las palabras, solo cuenta cuántas veces aparece cada una.\n",
    "  - Palabras comunes en todos los documentos pueden dominar la representación.\n",
    "\n",
    "- TfidfVectorizer:\n",
    "  - Convierte el texto en una matriz de TF-IDF (Term Frequency-Inverse Document Frequency).\n",
    "  - Pondera cada palabra según su frecuencia en el documento y su rareza en el corpus.\n",
    "  - Palabras que aparecen en muchos documentos reciben menor peso, resaltando las palabras más informativas de cada documento.\n",
    "\n",
    "Resumen:\n",
    "- CountVectorizer solo cuenta palabras.\n",
    "- TfidfVectorizer cuenta y pondera la importancia de cada palabra en el contexto del corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "580d0d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "HashVectorizer = HashingVectorizer(n_features=10, alternate_sign=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff3b4d9",
   "metadata": {},
   "source": [
    "El parámetro alternate_sign en HashingVectorizer controla si los valores de las características pueden ser positivos o negativos.\n",
    "\n",
    "Si alternate_sign=True (por defecto), los valores pueden ser positivos o negativos, alternando el signo según el hash.\n",
    "Si alternate_sign=False, todos los valores serán positivos.\n",
    "Esto afecta principalmente a algunos algoritmos de aprendizaje automático sensibles al signo de las características.\n",
    "Si no quieres valores negativos en tu matriz, usa alternate_sign=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9bb16d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81649658, 0.40824829, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.40824829, 0.        , 0.        ],\n",
       "       [0.1767767 , 0.35355339, 0.53033009, 0.        , 0.        ,\n",
       "        0.35355339, 0.35355339, 0.        , 0.53033009, 0.1767767 ],\n",
       "       [0.        , 0.26726124, 0.        , 0.26726124, 0.        ,\n",
       "        0.26726124, 0.26726124, 0.80178373, 0.        , 0.26726124]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HashingVectorizerTransformed = HashVectorizer.fit_transform(corpus)\n",
    "HashingVectorizerTransformed.toarray()  # Convert the hashed document-term matrix to an array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b5348b",
   "metadata": {},
   "source": [
    "¿Cuándo es mejor usar cada uno?\n",
    "\n",
    "- CountVectorizer:\n",
    "  - Úsalo cuando tienes un vocabulario pequeño o moderado y quieres contar la frecuencia absoluta de cada palabra.\n",
    "  - Es útil para modelos simples y cuando no te preocupa que palabras muy comunes dominen la representación.\n",
    "\n",
    "- TfidfVectorizer (o TfidfTransformer):\n",
    "  - Úsalo cuando quieres ponderar la importancia de las palabras, es decir, que las palabras frecuentes en todos los documentos tengan menos peso.\n",
    "  - Es mejor para tareas donde la relevancia de las palabras importa, como clasificación de texto, búsqueda o análisis de sentimientos.\n",
    "\n",
    "- HashingVectorizer:\n",
    "  - Úsalo cuando tienes un vocabulario muy grande o desconocido, o cuando los datos no caben en memoria.\n",
    "  - Es útil para procesamiento rápido y eficiente, pero no puedes recuperar el vocabulario original (las columnas no tienen nombres de palabras).\n",
    "  - Ideal para flujos de datos grandes o cuando la memoria es limitada.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
